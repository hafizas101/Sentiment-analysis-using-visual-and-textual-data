{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, sys, cv2, time, json, csv, re, pysrt\n",
    "from yolo_files.utils import *\n",
    "from keras.models import load_model\n",
    "from utils.datasets import get_labels\n",
    "from utils.preprocessor import preprocess_input\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "num is a very important variable. It controls how much frames per second of the video we are extracting so\n",
    "basically it is very computationally expensive and time consuming for long videos to perform frame by frame\n",
    "detection and processing. Hence we can periodically skip some frames. This is controlled by num variable. Setting\n",
    "num=1 would mean extract all frames. num = 2 means skip 1 frame and then extract the second and so on. num = 4\n",
    "would mean skip 3 frames and then extract 1 and then again skip 3 and so on.\n",
    "\"\"\"\n",
    "\n",
    "num = 1\n",
    "offset = 30\n",
    "emotion_code_mapping = {0:'angry',1:'disgust',2:'fear',3:'happy', 4:'sad',5:'surprise',6:'neutral'}\n",
    "input_video_path = os.path.join(os.getcwd(), \"input_video.mp4\")\n",
    "output_video_path = os.path.join(os.getcwd(), \"output.mp4\")\n",
    "current_path = os.getcwd()\n",
    "output_FPS = 4\n",
    "\n",
    "# stopword = stopwords.words('english')\n",
    "# wordnet_lemmatizer = WordNetLemmatizer()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\"\"\"\n",
    "Boundary for slighly and highly negative. Increasing it will increase number of slightly negatives\n",
    "but will decrease number of highly negatives. Same rule for positives.\n",
    "\"\"\"\n",
    "sentiment_threshold = 0.3\n",
    "num_period = 300\n",
    "current_path = os.getcwd()\n",
    "input_subtitle_path = os.path.join(os.getcwd(), \"climate.srt\")\n",
    "emotions = ['Highly Negative', 'Slightly Negative', 'Neutral', 'Slightly Positive', 'Highly Positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predict(frame, conf, emotion, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), COLOR_YELLOW, 2)\n",
    "\n",
    "    text = emotion+' {:.2f}'.format(conf)\n",
    "\n",
    "    # Display the label at the top of the bounding box\n",
    "    label_size, base_line = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "    top = max(top, label_size[1])\n",
    "    cv2.putText(frame, text, (left, top - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_WHITE, 1)\n",
    "    return\n",
    "\n",
    "def convert_frames_to_video(frames):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
    "    height, width, channels = frames[0].shape\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, output_FPS, (width, height))\n",
    "    for i, ff in enumerate (frames):\n",
    "        out.write(ff)\n",
    "    out.release\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n",
    "\n",
    "def clean_words(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "#     removing_stopwords = [word for word in word_tokens if word not in stopword]\n",
    "#     lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in removing_stopwords]\n",
    "    wordsa=[word.lower() for word in words if word.isalpha()]\n",
    "    return wordsa\n",
    "\n",
    "\n",
    "def calculate_polarity_and_intensity(d, rep):\n",
    "    if d['neu']==1.0:\n",
    "        emotional_intensity = \"Neutral\"\n",
    "        polarity = 0.0\n",
    "        rep[2] = rep[2] + 1\n",
    "    elif ((d['neg'] < sentiment_threshold) & (d['pos'] == 0.0)):\n",
    "        emotional_intensity = \"Slightly Negative\"\n",
    "        polarity = -1*d['neg']\n",
    "        rep[1] = rep[1] + 1\n",
    "    elif ((d['neg'] > sentiment_threshold) & (d['pos'] == 0.0)):\n",
    "        emotional_intensity = \"Highly Negative\"\n",
    "        polarity = -1*d['neg']\n",
    "        rep[0] = rep[0] + 1\n",
    "    elif ((d['neg'] == 0.0) & (d['pos'] < sentiment_threshold)):\n",
    "        emotional_intensity = \"Slightly Positive\"\n",
    "        polarity = d['pos']\n",
    "        rep[3] = rep[3] + 1\n",
    "    elif ((d['neg'] == 0.0) & (d['pos'] > sentiment_threshold)):\n",
    "        emotional_intensity = \"Highly Positive\"\n",
    "        polarity = d['pos']\n",
    "        rep[4] = rep[4] + 1\n",
    "    else:\n",
    "        values = [d['neg'], d['neu'], d['pos']]\n",
    "        dominant = max(values)\n",
    "        \n",
    "        if values.index(dominant) == 0:\n",
    "            polarity = -1*d['neg']\n",
    "            if dominant > sentiment_threshold:\n",
    "                emotional_intensity = \"Highly Negative\"\n",
    "                rep[0] = rep[0] + 1\n",
    "            else:\n",
    "                emotional_intensity = \"Slightly Negative\"\n",
    "                rep[1] = rep[1] + 1\n",
    "        elif values.index(dominant) == 1:\n",
    "            polarity = 0.0\n",
    "            emotional_intensity = \"Neutral\"\n",
    "            rep[0] = rep[0] + 1\n",
    "        else:\n",
    "            polarity = d['pos']\n",
    "            if dominant < sentiment_threshold:\n",
    "                emotional_intensity = \"Slightly Positive\"\n",
    "                rep[3] = rep[3] + 1\n",
    "            else:\n",
    "                emotional_intensity = \"Highly Positive\"\n",
    "                rep[4] = rep[4] + 1\n",
    "    return polarity, emotional_intensity, rep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_time_stamp(l):\n",
    "    if l[:2].isnumeric() and l[2] == ':':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def has_letters(line):\n",
    "    if re.search('[a-zA-Z]', line):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def has_no_text(line):\n",
    "    l = line.strip()\n",
    "    if not len(l):\n",
    "        return True\n",
    "    if l.isnumeric():\n",
    "        return True\n",
    "    if is_time_stamp(l):\n",
    "        return True\n",
    "    if l[0] == '(' and l[-1] == ')':\n",
    "        return True\n",
    "    if not has_letters(line):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_lowercase_letter_or_comma(letter):\n",
    "    if letter.isalpha() and letter.lower() == letter:\n",
    "        return True\n",
    "    if letter == ',':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_up(lines):\n",
    "    \"\"\"\n",
    "    Get rid of all non-text lines and\n",
    "    try to combine text broken into multiple lines\n",
    "    \"\"\"\n",
    "    new_lines = []\n",
    "    for line in lines[1:]:\n",
    "        if has_no_text(line):\n",
    "            continue\n",
    "        elif len(new_lines) and is_lowercase_letter_or_comma(line[0]):\n",
    "            new_lines[-1] = new_lines[-1].strip() + ' ' + line\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mod-et-emo-001 ==> Video Splitting in Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames Per Second: 25.0\n",
      "Total number of frames read: 153\n",
      "Time taken in reading the frames: 0.38521599769592285 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Frames Per Second: \"+str(FPS))\n",
    "\n",
    "frames = []\n",
    "start = time.time()\n",
    "count = 0\n",
    "frame_originals = []\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    count = count + 1\n",
    "    if not ret:\n",
    "        break\n",
    "    if count % num == 0:        \n",
    "        frames.append(frame)\n",
    "#         cv2.imshow(\"Original\", frame)\n",
    "#         cv2.waitKey(0)\n",
    "end = time.time()\n",
    "print(\"Total number of frames read: \"+str(len(frames)))\n",
    "print(\"Time taken in reading the frames: {} seconds\".format(end-start))\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mod-et-emo-002 ==> Faces and mood detection per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arslan/.conda/envs/mood3/lib/python3.7/site-packages/keras/engine/saving.py:350: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in processing 153 frames: 120.295 seconds\n"
     ]
    }
   ],
   "source": [
    "cfg = './yolo_files/yolov3-face.cfg'\n",
    "weights = './yolo_files/yolov3-wider_16000.weights'\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(cfg, weights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "faces = []\n",
    "\n",
    "\n",
    "emotion_model_path = './models/emotion_model.hdf5'\n",
    "# emotion_labels = get_labels('fer2013')\n",
    "# print(emotion_labels)\n",
    "emotion_classifier = load_model(emotion_model_path)\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "count_repetition = np.array([0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "X_position = []\n",
    "Y_position = []\n",
    "Frame = []\n",
    "Width = []\n",
    "Height = []\n",
    "Emotion_code = []\n",
    "Emotion_name = []\n",
    "Score = []\n",
    "start = time.time()\n",
    "for i in range (len(frames)):\n",
    "    blob = cv2.dnn.blobFromImage(frames[i], 1 / 255, (IMG_WIDTH, IMG_HEIGHT),[0, 0, 0], 1, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(get_outputs_names(net))\n",
    "\n",
    "    # Remove the bounding boxes with low confidence\n",
    "    frame_faces = post_process(frames[i], outs, CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "    if len(frame_faces) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        face_imgs = []\n",
    "        for j, f in enumerate(frame_faces):\n",
    "            Frame.append(i+1)\n",
    "            faces.append(f)\n",
    "            [left, top, w, h] = f\n",
    "            X_position.append(left)\n",
    "            Y_position.append(top)\n",
    "            Width.append(w)\n",
    "            Height.append(h)\n",
    "#             original_face = frames[i][top : top+h, left:left+w]\n",
    "#             cv2.imwrite(str(j+1)+\".jpg\", original_face)\n",
    "#             offset_face = frames[i][top-offset : top+h+offset , left-offset:left+w+offset]\n",
    "#             cv2.imwrite(str(j+1)+\"_offset.jpg\", offset_face)\n",
    "            face_imgs.append(frames[i][top-offset : top+h+offset , left-offset:left+w+offset])\n",
    "#             cv2.imshow(\"Faces\", face_imgs[j])\n",
    "#             cv2.waitKey(0)\n",
    "            gray_face = cv2.cvtColor(face_imgs[j], cv2.COLOR_BGR2GRAY)\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "            gray_face = preprocess_input(gray_face, True)\n",
    "            gray_face = np.expand_dims(gray_face, 0)\n",
    "            gray_face = np.expand_dims(gray_face, -1)\n",
    "            emotion_prediction = emotion_classifier.predict(gray_face)\n",
    "            emotion_probability = np.max(emotion_prediction)\n",
    "            Score.append(emotion_probability)\n",
    "            emotion_label_arg = np.argmax(emotion_prediction)\n",
    "            Emotion_code.append(emotion_label_arg)\n",
    "            count_repetition[emotion_label_arg] = count_repetition[emotion_label_arg] + 1\n",
    "            emotion_text = emotion_code_mapping[emotion_label_arg]\n",
    "            Emotion_name.append(emotion_text)\n",
    "            draw_predict(frames[i], emotion_probability, emotion_text, left, top, left+w, top+h)\n",
    "\n",
    "#         cv2.imshow(\"Faces\", frames[i])\n",
    "#         cv2.waitKey(0)\n",
    "end = time.time()\n",
    "print(\"Time taken in processing {0:1.0f} frames: {1:2.3f} seconds\".format(len(frames), end-start))\n",
    "convert_frames_to_video(frames)\n",
    "cv2.destroyAllWindows()\n",
    "project2_dict = {'Frame': Frame, 'X_position': X_position, 'Y_position': Y_position, 'Width': Width, 'Height': Height,\n",
    "                 'Emotion_code': Emotion_code, 'Emotion_name': Emotion_name, 'Score': Score}\n",
    "\n",
    "if os.path.exists(os.path.join(current_path, \"mod-et-emo-002.csv\")):\n",
    "    os.remove(os.path.join(current_path, \"mod-et-emo-002.csv\"))\n",
    "df = pd.DataFrame(data=project2_dict)\n",
    "df.to_csv('mod-et-emo-002.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mod-et-emo-003 ==> Aggregation of emotions detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Emotion Code: 4\n",
      "Most Frequent Emotion: sad\n",
      "Final result: 0.5324261444082552\n"
     ]
    }
   ],
   "source": [
    "# print(count_repetition)\n",
    "\n",
    "aggregated_emotion_code = np.argmax(count_repetition)\n",
    "print(\"Aggregated Emotion Code: \"+str(aggregated_emotion_code))\n",
    "aggregated_emotion_name = emotion_code_mapping[aggregated_emotion_code]\n",
    "print(\"Most Frequent Emotion: \"+str(aggregated_emotion_name))\n",
    "num = len(Emotion_code)\n",
    "total_rep = 0\n",
    "total = 0\n",
    "for i in range (num):\n",
    "    total = total + Score[i]*count_repetition[Emotion_code[i]]\n",
    "    total_rep = total_rep + count_repetition[Emotion_code[i]]\n",
    "    \n",
    "final_code = total/total_rep\n",
    "print(\"Final result: \"+str(final_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mod-et-emo-004 ==> Mood polarity detection in subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_subtitle_path, errors='replace') as f:\n",
    "    lines = f.readlines()\n",
    "    new_lines = clean_up(lines)\n",
    "\n",
    "emotional_intensity = []\n",
    "polarity = []\n",
    "sentences = []\n",
    "count_repitition = [0, 0, 0, 0, 0]\n",
    "count = 0\n",
    "for i, line in enumerate(new_lines):\n",
    "    words = clean_words(line)\n",
    "    data = \"\"\n",
    "    for j, w in enumerate(words):\n",
    "        data = data + \" \"+ w    \n",
    "    \n",
    "    if data == \"\":\n",
    "        continue\n",
    "    sents = nltk.sent_tokenize(data)\n",
    "    for s in sents:\n",
    "        sentences.append(s)\n",
    "        d = analyzer.polarity_scores(s)\n",
    "        p, e, count_repitition = calculate_polarity_and_intensity(d, count_repitition)\n",
    "        polarity.append(p)\n",
    "        emotional_intensity.append(e)\n",
    "\n",
    "if os.path.exists(os.path.join(current_path, \"mod-et-emo-004.csv\")):\n",
    "    os.remove(os.path.join(current_path, \"mod-et-emo-004.csv\"))\n",
    "if len(sentences) == len(emotional_intensity):\n",
    "    df = pd.DataFrame(data = {'Sentences': sentences, 'Emotional Intensity': emotional_intensity, 'Polarity': polarity})\n",
    "    df.to_csv('mod-et-emo-004.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mod-et-emo-005 ==> Association of the temporary emotional intensity in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1103\n",
      "Time period in milliseconds: 1356\n",
      "Words per time period: 4\n"
     ]
    }
   ],
   "source": [
    "subs = pysrt.open(input_subtitle_path)\n",
    "x = subs[len(subs)-1]\n",
    "[hour, minute, sec] = [x.end.hours, x.end.minutes, x.end.seconds]\n",
    "total_duration = hour*3600000 + minute*60000 + sec*1000\n",
    "\n",
    "text = \"\"\n",
    "for i in range (len(subs)):\n",
    "    a = subs[i]\n",
    "    text = text +\" \"+ a.text\n",
    "    \n",
    "words = clean_words(text)\n",
    "num_words = len(words)\n",
    "print(\"Total words: \"+str(num_words))\n",
    "words_per_duration = num_words/total_duration\n",
    "time_period = int(total_duration/num_period)\n",
    "print(\"Time period in milliseconds: \"+str(time_period))\n",
    "words_period = int(time_period*words_per_duration)\n",
    "print(\"Words per time period: \"+str(words_period+1))\n",
    "\n",
    "period_num = []\n",
    "from_to = []\n",
    "polarity = []\n",
    "emotional_intensity = []\n",
    "strings = []\n",
    "starting = 0\n",
    "ending = time_period\n",
    "\n",
    "start = 0\n",
    "stop = words_period+1\n",
    "count_repitition = [0, 0, 0, 0, 0]\n",
    "for i in range(num_period):\n",
    "    all_words = words[start:stop]\n",
    "    data = \"\"\n",
    "    for j, w in enumerate(all_words):\n",
    "        data = data + \" \"+ w    \n",
    "    \n",
    "    if data == \"\":\n",
    "        continue\n",
    "    period_num.append(i)\n",
    "    from_to.append((starting, ending))\n",
    "    strings.append(data)\n",
    "    d = analyzer.polarity_scores(data)\n",
    "    p, e, count_repitition = calculate_polarity_and_intensity(d, count_repitition)\n",
    "    polarity.append(p)\n",
    "    emotional_intensity.append(e)    \n",
    "    \n",
    "    start = stop\n",
    "    stop = start + words_period+1\n",
    "    starting = ending\n",
    "    ending = starting + time_period\n",
    "    \n",
    "if os.path.exists(os.path.join(current_path, \"mod-et-emo-005.csv\")):\n",
    "    os.remove(os.path.join(current_path, \"mod-et-emo-005.csv\"))\n",
    "df = pd.DataFrame(data = {'Sentences': strings, 'Time Period':period_num, 'Time from, time to (in miliseconds)':from_to, 'Detected polarity': polarity, 'Emotional_Intensity': emotional_intensity})\n",
    "df.to_csv('mod-et-emo-005.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mod-et-emo-006 ==> Polarity aggregation in subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks: [4, 3, 1, 2, 5]\n",
      "Final Result: [0.11956521739130435, 0.18478260869565216, 0.3804347826086957, 0.2717391304347826, 0.043478260869565216]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ranking is being performed based upon how many times an emotion appears. Most frequent will get rank 1 and least\n",
    "frequent will get rank 5.\n",
    "\"\"\"\n",
    "\n",
    "ranks = [0,0,0,0,0]\n",
    "rep = count_repitition.copy()\n",
    "total = sum(rep)\n",
    "scores = []\n",
    "for i in range (len(rep)):\n",
    "    scores.append(rep[i]/total)\n",
    "rank = 1\n",
    "for i in range (len(count_repitition)):\n",
    "    value = max(count_repitition)\n",
    "    ranks [rep.index(value)] = ranks [rep.index(value)] + rank\n",
    "    count_repitition.remove(value)\n",
    "    rank = rank + 1\n",
    "    \n",
    "print(\"Ranks: \"+str(ranks))\n",
    "print(\"Final Result: \"+str(scores))\n",
    "\n",
    "if os.path.exists(os.path.join(current_path, \"mod-et-emo-006.csv\")):\n",
    "    os.remove(os.path.join(current_path, \"mod-et-emo-006.csv\"))\n",
    "df = pd.DataFrame(data = {'Emotions': emotions, 'Ranking':ranks, 'Final Result':scores})\n",
    "df.to_csv('mod-et-emo-006.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
